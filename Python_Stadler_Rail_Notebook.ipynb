{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selinealdridge/KETE-HS22-WORK/blob/main/Python_Stadler_Rail_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bukYldAqqWW2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN9ZJvkPrlJD"
      },
      "source": [
        "##  Python/Juypter Notebook \n",
        "### Transportnetz-Struktur – From Data To Decisions: \"Transportwirtschaft\" \n",
        "####Auswertung der in Auftrag gegebenen europaweiten Strassentransporte von Halb- und Fertigfabrikaten einer Produktionsfirma\n",
        "\n",
        "\n",
        "Dies ist ein auf [Colab Python IDE](https://colab.research.google.com/) basierendes [jupyter notebook](http://jupyter.org/) (früher als ipython notebook bezeichnet). \n",
        "\n",
        "\n",
        "Quellen: \n",
        "+ Nachschlagewerk: https://www.lis.eu/logistik-transport-lexikon/\n",
        "\n",
        "+ Gorman, M.F., Clarke, JP., de Koster, R. et al. Emerging practices and research issues for big data analytics in freight transportation. Marit Econ Logist (2023). https://doi.org/10.1057/s41278-023-00255-z\n",
        "\n",
        "+ Heinbach, C., Beinke, J., Kammler, F. et al. Data-driven forwarding: a typology of digital platforms for road freight transport management. Electron Markets 32, 807–828 (2022). https://doi.org/10.1007/s12525-022-00540-4\n",
        "\n",
        "+ Poliak, M., Poliakova, A., Svabova, L., Zhuravleva, A., N., & Nica, E. (2021). Competitiveness of Price in International Road Freight Transport. Journal ofCompetitiveness, 13(2), 83–98. https://doi.org/10.7441/ joc.2021.02.05 \n",
        "\n",
        "+ Wang, A. Y., Wang, D., Drozdal, J., Liu, X., Park, S., Oney, S., & Brooks, C. (2021). What Makes a Well-Documented Notebook? A Case Study of Data Scientists’ Documentation Practices in Kaggle. Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, 1–7. https://doi.org/10.1145/3411763.3451617 \n",
        "\n",
        "\n",
        "Data:\n",
        "+ BINA_FS23.csv von Alpega Transportmanagementsystem (TMS) extrahiert vom Stadler Rail Server\n",
        "\n",
        "*Hinweis: Sie müssen diesen Datensatz in Ihren Colab-Arbeitsbereich hochladen, bevor Sie mit der Programmausführung beginnen!*\n",
        "  \n",
        "---\n",
        "Inhalt:\n",
        "1. Problemstellung\n",
        "2. Datenbereinigung\n",
        "3. Datenverarbeitung\n",
        "4. Datenvisualisierung\n",
        "\n",
        "--- \n",
        "\n",
        "Autorinnen: \n",
        "*   Cynthia Mascherpa\n",
        "*   Ho Yin Lam\n",
        "*   Seline Aldridge\n",
        "\n",
        "Verlauf: \n",
        "*   v1, März 2023, chs --- Initialversion für BINA FS23\n",
        "*   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problemstellung"
      ],
      "metadata": {
        "id": "dCWXU5l-3hcv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnj3kTZfrlJJ"
      },
      "source": [
        "\n",
        "\n",
        "Die Spedition der Organisation fragt nach einer Auswertung der Transportdaten. Die interne BA/BI-Software kann von den Mitarbeitenden nicht bedient werden, da ein Schulungstermin durch den Softwareanbieter noch immer aussteht. Die Studierenden helfen der Organisation bei der Erstellung der Auswertung, indem sie die Fragestellungen in Form von statistischen Visualisierungen beantworten können. Die Auswertung zeigt der Organisation erstmals den Ist-Zustand auf und hilft der Organisation dabei, Verbesserungsmöglichkeiten für die zukünftige Entwicklung der Logistik zu erkennen.\n",
        "\n",
        "Theoretischer Hintergrund/Vorgehen: Die Transportwirtschaft beschäftigt sich mit dem Transport von Gütern. Es gibt verschiedene Gründe für einen Transport und sobald ein Transport von der Organisation organisiert wird, ist er Teil des Datensatzes. Gründe für den Transport sind:\n",
        "- die Organisation hat einen externen Dienstleister beauftragt, um Güter von einem vordefinierten Beladungspunkt zu einem Entladungspunkt zu transportieren.\n",
        "- Interwerk-Transporte: Zwischen zwei Produktionsstandorten finden ein Austausch von Halb- oder Fertigfabrikaten statt. Der Transport wird über die Transportabteilung organisiert.\n",
        "- Transport an den Käufer des Endproduktes \n",
        "\n",
        "Um den Datensatz optimal verarbeiten zu können, ist es wichtig, das Thema theoretisch zu erläutern und sich auf den spezifischen Ansatzpunkt zu konzentrieren, der für die Organisation relevant ist. Demensprechende werden in diesem Collaboraty, theoretische Inputs bei den entsprechenden Code-Zeilen hinzugefügt, um das Verständis zu verbessern.\n",
        "\n",
        "HINWEIS: Im Fokus der Auswertung werden Transporte von oder ab dem Werk in St. Margrethen mit PLZ 9430 angeschaut, da es sich dabei um das Werk handelt bei welchem die genannte Speditionsabteilung angesiedelt ist.\n",
        "\n",
        "\\\n",
        "\n",
        "### Fragestellung von der Stadler Rail AG\n",
        "\n",
        "*\tGibt es eine Saisonalität/sich wiederholendes Muster in den Strassentransporten (Halbfertigfabrikaten und den Rohmaterialien) von FTL, LTL und Stückgutladungen?\n",
        "\n",
        "\\\n",
        "\n",
        "### Fragestellungen der Studierenden\n",
        "\n",
        "*\tWelche Transportstrecken haben eine hohe Frequentierung ? (bspw. CH 9430 nach PL 08110)\n",
        "*\tWie viele Transporte wurden insgesamt, im Monatsdurchschnitt, Tagesdurchschnitt ausgeführt?\n",
        "*\tWie viele Tage liegen zwischen der Beladung und der Entladung unter Berücksichtigung des Beladungs- und Entladungsortes?\n",
        "*\tWie sieht das Transportnetz vom Jahr 2022 in Form einer Karte aus?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Einleitung\n",
        "\n",
        "Die Bearbeitung soll sich an den Schritten 1-4 der CPA Management Accounting Guideline „From Data to Decisions“1 orientieren."
      ],
      "metadata": {
        "id": "z6pWzRTBrMOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Umgebung einrichten/prüfen und notwendige Bibliotheken importieren:"
      ],
      "metadata": {
        "id": "RI5Fg7iYNYEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "gbmn9zcf0HDs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "# wechsel ins (colab lokale verzeichnis)\n",
        "%cd /content/sample_data    \n",
        "# anzeige der vorhandenen dateien\n",
        "%ls"
      ],
      "metadata": {
        "id": "A4fONE4JL7VX",
        "outputId": "b85cd871-ff02-4ef7-817d-ea23db69889f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BINA_FS23.csv  \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\n",
            "/content/sample_data\n",
            "BINA_FS23.csv  \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "V8AFAb8iMy0p",
        "outputId": "54d3fb74-3fad-4381-8212-3bcb54d4cde4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BINA_FS23.csv  \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data from Github Repository into dataframe variable \n",
        "df = pd.read_csv('https://github.com/selinealdridge/BINA23_Stadler_Rail_Semesterarbeit/raw/main/BINA_FS23.csv', sep=',').copy()\n",
        "df.head()\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "pxqQwo7XGUSM",
        "outputId": "408dffee-9744-4245-9c39-f962d7636513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e9201b5a0bbf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading Data from Github Repository into dataframe variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/selinealdridge/BINA23_Stadler_Rail_Semesterarbeit/raw/main/BINA_FS23.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "v8og_3Ixkrso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Hh9fCHXmy7ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "anw58SbyGUET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Datenbereinigung"
      ],
      "metadata": {
        "id": "3LGiyKL73WIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B) Spaltenbezeichnung bereinigen"
      ],
      "metadata": {
        "id": "T6MUmo7FiQD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spalte löschen, keine Angaben drin\n",
        "df = df.drop(['Unnamed: 13'], axis=1) \n"
      ],
      "metadata": {
        "id": "qZo5edGc15KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spalte umbenennen für bessere Verständlichkeit\n",
        "\n",
        "df.rename(columns={'Status Consignment Collected \\n(LS160) DateTime Last by Event': 'Beladungsdatum', \n",
        "                   'Transport\\nMode': 'Transport_Modus', \n",
        "                   'Origin Postal Code': 'Start_PLZ', \n",
        "                   'Origin Country': 'Start_Land_ISO', \n",
        "                   'Dest Country': 'Endstation_Land_ISO',\n",
        "                   'Dest Postal Code': 'Endstation_PLZ',\n",
        "                   'Ref': 'Referenz',\n",
        "                   'Weight/Volume': 'Lademeter'}, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "5VuHyEec25-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###C) Irrelavente Spalten/Zeilen bereinigen"
      ],
      "metadata": {
        "id": "kxLZyC39igIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit = Loading Meter, ergo wurden die Werte die die Lademeter zeigen mit dem Namen Lademeter (LDM) gekennzeichnet\n",
        "# Freight Cost All in ist gemäss Angaben der Organisiation nicht wichtig\n",
        "# Referenz der Currency ist nicht nötig\n",
        "df = df.drop(['Currency','Unit','Freight Cost\\nAll in','Transport_Modus'], axis=1)\n"
      ],
      "metadata": {
        "id": "9tUy-45S3Imf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NaN-Werte löschen"
      ],
      "metadata": {
        "id": "fDnU-vzKHITT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count = df['Lademeter'].isna().sum()\n",
        "total_rows = df.shape[0]\n",
        "nan_ratio = nan_count / total_rows\n",
        "print (nan_ratio)"
      ],
      "metadata": {
        "id": "Az38zP3J0ZtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 % alle Zeilen, habe keine Angaben zu den Lademetern. Sie werden gelöscht."
      ],
      "metadata": {
        "id": "W3Wi6ob10_Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Lademeter'], inplace=True)\n"
      ],
      "metadata": {
        "id": "aFIhVKoZ1OIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count1 = df['Start_Land_ISO'].isna().sum()\n",
        "total_rows1 = df.shape[0]\n",
        "nan_ratio1 = nan_count1 / total_rows1\n",
        "print (nan_ratio1)"
      ],
      "metadata": {
        "id": "P8TA7HtK1rHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 % alle Zeilen, habe keine Angaben zu den Abfahrtsort. Keine Zeile muss gelöscht."
      ],
      "metadata": {
        "id": "zNvJYj1n16RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count1 = df['Endstation_Land_ISO'].isna().sum()\n",
        "total_rows1 = df.shape[0]\n",
        "nan_ratio1 = nan_count1 / total_rows1\n",
        "print (nan_ratio1)"
      ],
      "metadata": {
        "id": "1ESFcYdu2Kb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 % alle Zeilen, habe keine Angaben zu der Endstation. Keine Zeile muss gelöscht."
      ],
      "metadata": {
        "id": "CJfN9umd2eDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count1 = df['Beladungsdatum'].isna().sum()\n",
        "total_rows1 = df.shape[0]\n",
        "nan_ratio1 = nan_count1 / total_rows1\n",
        "print (nan_ratio1)"
      ],
      "metadata": {
        "id": "Lb_cNXPtGqCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "32 % aller Zeilen, habe keine Angaben zum Beladungsdatum. Die Zeilen werden gelöscht."
      ],
      "metadata": {
        "id": "gTMADdMaXySZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Beladungsdatum'], inplace=True)"
      ],
      "metadata": {
        "id": "39vQHSGUG9L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count1 = df['Entladungsdatum'].isna().sum()\n",
        "total_rows1 = df.shape[0]\n",
        "nan_ratio1 = nan_count1 / total_rows1\n",
        "print (nan_ratio1)"
      ],
      "metadata": {
        "id": "SR3tnh2wGxzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die restlichen 3% der Zeilen, ohne Entladungsdatum werden gelöscht."
      ],
      "metadata": {
        "id": "iCvmO8LzYIzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Entladungsdatum'], inplace=True)"
      ],
      "metadata": {
        "id": "IhdQgLFvHBaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df. info()\n"
      ],
      "metadata": {
        "id": "tDxEenY-YSt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###D) Hinzufügen relevanter Information und Formatierungen\n",
        "--- \n",
        "Quellen für das hinzufügen von Ländernamen auf Basis des ISO Code: \n",
        "+ See Python [pycountry](https://pypi.org/project/pycountry/) library for ISO country, subdivision, language, currency and script definitions and their translations\n",
        "--- "
      ],
      "metadata": {
        "id": "iDTkxuJ6gD8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hinzufügen der Abkürzungen für Produktionswerken"
      ],
      "metadata": {
        "id": "jUl1tGPcDOSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column called 'Production Site' based on the Start and End location conditions\n",
        "df.loc[(df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'].isin(['9565', '8570', '9323', '8583', '8560'])), 'Production Site Start'] = 'STAG'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'].isin(['9565', '8570', '9323', '8583', '8560'])), 'Production Site Endstation'] = 'STAG'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'].isin(['9430', '9423'])), 'Production Site Start'] = 'STAR'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'].isin(['9430', '9423'])), 'Production Site Endstation'] = 'STAR'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'].isin(['8404'])), 'Production Site Start'] = 'STAWI'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'].isin(['8404'])), 'Production Site Endstation'] = 'STAWI'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'].isin(['2504'])), 'Production Site Start'] = 'SSG'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'].isin(['2504'])), 'Production Site Endstation'] = 'SSG'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'DE') & (df['Start_PLZ'].isin(['13158', '13509', '10247' ])), 'Production Site Start'] = 'STAP'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'DE') & (df['Endstation_PLZ'].isin(['13158', '13509', '10247'])), 'Production Site Endstation'] = 'STAP'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'PL') & (df['Start_PLZ'].isin(['08-110', '08110', '08-11' ])), 'Production Site Start'] = 'STAPS'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'PL') & (df['Endstation_PLZ'].isin(['08-110', '08110', '08-11'])), 'Production Site Endstation'] = 'STAPS'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'PL') & (df['Start_PLZ'].isin(['63-000 ', '63000'])), 'Production Site Start'] = 'STASA'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'PL') & (df['Endstation_PLZ'].isin(['63-000 ', '63000'])), 'Production Site Endstation'] = 'STASA'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'HU') & (df['Start_PLZ'].isin(['5000'])), 'Production Site Start'] = 'STASK'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'HU') & (df['Endstation_PLZ'].isin(['5000'])), 'Production Site Endstation'] = 'STASK'\n",
        "\n",
        "df.loc[(df['Start_Land_ISO'] == 'ES') & (df['Start_PLZ'].isin(['46550'])), 'Production Site Start'] = 'STAV'\n",
        "df.loc[(df['Endstation_Land_ISO'] == 'ES') & (df['Endstation_PLZ'].isin(['46550'])), 'Production Site Endstation'] = 'STAV'\n",
        "\n",
        "# shift column 'Production Site Start' to second position and 'Production Site Endstation' to sixth position\n",
        "df.insert(2, 'Production Site Start', df.pop('Production Site Start'))\n",
        "df.insert(5, 'Production Site Endstation', df.pop('Production Site Endstation'))"
      ],
      "metadata": {
        "id": "0KLYaK6rDa_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Korrekte Formatierung des Timestamp"
      ],
      "metadata": {
        "id": "KwuEj3pEbK62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the data types of the \"Beladungsdatum\" and \"Entladungsdatum\" columns\n",
        "\n",
        "print(\"Data type of Beladungsdatum column:\", df[\"Beladungsdatum\"].dtype)\n",
        "print(\"Data type of Entladungsdatum column:\", df[\"Entladungsdatum\"].dtype)\n",
        "\n",
        "#Convert the \"Beladungsdatum\" and \"Entladungsdatum\" columns to datetime objects with correct formatting\n",
        "\n",
        "df[\"Beladungsdatum\"] = pd.to_datetime(df[\"Beladungsdatum\"], format='%d.%m.%Y')\n",
        "df[\"Entladungsdatum\"] = pd.to_datetime(df[\"Entladungsdatum\"], format='%d.%m.%Y')\n",
        "\n",
        "#Convert the \"Startzeit\" and \"Endzeit\" columns to datetime objects and combine them with the dates\n",
        "\n",
        "df[\"Start\"] = pd.to_datetime(df[\"Beladungsdatum\"].dt.date.astype(str) + \" \" + df[\"Startzeit\"])\n",
        "df[\"End\"] = pd.to_datetime(df[\"Entladungsdatum\"].dt.date.astype(str) + \" \" + df[\"Endzeit\"])\n",
        "\n",
        "#Calculate duration in hours and days\n",
        "\n",
        "df['Dauer'] = df['End'] - df['Start']\n",
        "df['Tage'] = df['Dauer'].dt.days\n",
        "df['Stunden'] = df['Dauer'].dt.seconds // 3600\n",
        "\n",
        "#Combine days and hours in one column\n",
        "\n",
        "df['Dauer (Tage,Stunden)'] = df['Tage'].astype(str) + ' Tage' + ',' + df['Stunden'].astype(str) + ' Stunden'\n",
        "\n"
      ],
      "metadata": {
        "id": "Skhg4CxJazGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hinzufügen der Ländernamen"
      ],
      "metadata": {
        "id": "tXv3wbmpbQFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycountry\n",
        "import pycountry"
      ],
      "metadata": {
        "id": "33igS-Hbf6m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a local function to determine the ISO country name from an ISO country code\n",
        "# try-except blocks for exception handling when the passed iso_code parameter is invalid or the pycountry.countries.get funtion returns not a valid value\n",
        "\n",
        "def get_country_name(iso_code):\n",
        "  try:\n",
        "    iso_country = pycountry.countries.get(alpha_2=str(iso_code))\n",
        "    country_name = iso_country.name\n",
        "  except:\n",
        "    country_name = None\n",
        "  return country_name\n",
        "  "
      ],
      "metadata": {
        "id": "OUx8BLORtIKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the function *get_country_name*\n",
        "print(get_country_name('DE'))"
      ],
      "metadata": {
        "id": "dANGXQwkW4-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column based on values from other columns in a dataframe using the *apply* method\n",
        "df['Start_Land_Name'] = df.apply(lambda row: get_country_name(row['Start_Land_ISO']),axis=1)"
      ],
      "metadata": {
        "id": "f0ww3ee2WYHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column based on values from other columns in a dataframe using the *apply* method\n",
        "df['Endstation_Land_Name'] = df.apply(lambda row: get_country_name(row['Endstation_Land_ISO']),axis=1)\n"
      ],
      "metadata": {
        "id": "ys7ws8PyXvgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shift column 'Start_Land_Name' to second position and 'Endstation_Land_Name' to sixth position\n",
        "df.insert(2, 'Start_Land_Name', df.pop('Start_Land_Name'))\n",
        "df.insert(5, 'Endstation_Land_Name', df.pop('Endstation_Land_Name'))"
      ],
      "metadata": {
        "id": "p2Vxzz5dePxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wir suchen alle einzigartigen Werte in den Ländern, die es gibt.\n",
        "\n",
        "unique_values = df['Start_Land_Name'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "YmACbcvtlgvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wir suchen alle einzigartigen Werte in den Ländern, die es gibt.\n",
        "\n",
        "unique_values = df['Endstation_Land_Name'].unique()\n",
        "print(unique_values)\n"
      ],
      "metadata": {
        "id": "2Xqikot-mABA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance zw. den Destinationen hinzufügen\n"
      ],
      "metadata": {
        "id": "ojhrGYeKY53x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###E) Unterscheidung in Interwerk und nicht-Interwerk-Transporte\n",
        "The differentiation between transports that happen between production sites (e.g. one site in Poland and one in Switzerland) and those that do not happen between production sites is important for freight forwarding department. Because of the Cost and pricing: \n",
        "\n",
        "Transports between production sites may involve different cost structures and pricing models than other types of shipments. For example, logistics companies may offer discounts or special rates for regular shipments between production sites. Therefore, logistics companies need to be able to calculate and manage costs effectively to remain competitive and profitable. Therefore the freight forwarding department needs to be able to tell who high the volum is."
      ],
      "metadata": {
        "id": "ql5vVlB7lJrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###F) Kategorisierung der Transporte in FTL, LTL, Stückgut\n",
        "\n",
        "Hinweis: In dem Datensatz werden die Lademeter pro Sendung ersichtlich. Der Begriff Lademeter (LDM) ist eine Masseinheit in der Transport- und Logistikbranche, um die Ladefläche für zu transportierende Güter anzugeben. Folgende Kategorisierung muss für eine erhöhte Übersichtlichkeit der Transporte vorgenommen werden: Full Truck Load (FTL) (o.a. Komplettladung), Less Than Truck Load (LTL), Stückgut (engl. Groupage). Wie kommt man zu dieser Kategorisierung? \n",
        "\n",
        "Stückgut: bis 2 Lademeter  \n",
        "LTL: von 2 bis 11.6 Lademeter  \n",
        "FTL: ab 11.6 Lademeter\n",
        "\n",
        "Die Kategorisierung ist einerseits für die Preisberechnung wichtig, aber auch für die Anzahl Transporttage, die der LKW unterwegs ist, sowie für die Datenverarbeitung/Visualisierung.  "
      ],
      "metadata": {
        "id": "R6XX96ROjv1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transport-Kategorie Spalte hinzufügen\n",
        "\n",
        "df['Transport-Kategorie'] = df['Lademeter'].apply(lambda x: 'Stückgut' if x <= 2 else 'LTL' if x <= 11.6 else 'FTL')"
      ],
      "metadata": {
        "id": "yP8BocKdgNzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Datenverarbeitung/Datenvisualisierung"
      ],
      "metadata": {
        "id": "j3BV1YfC-psX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fragestellung von der Stadler Rail AG\n",
        "\n",
        "1. Gibt es eine Saisonalität/sich wiederholendes Muster in den Strassentransporten (Halbfertigfabrikaten und den Rohmaterialien) von FTL, LTL und Stückgutladungen?\n",
        "(Fokus auf das Produktionswerk in St. Margrethen, CH-9430)\n",
        "\n",
        "###Fragestellungen der Studierenden\n",
        "\n",
        "Welche Transportstrecken haben eine hohe Frequentierung ? (bspw. CH 9430 nach PL 08110)\n",
        "\n",
        "Wie viele Transporte wurden insgesamt, im Monatsdurchschnitt, Tagesdurchschnitt ausgeführt?\n",
        "\n",
        "Wie viele Tage liegen zwischen der Beladung und der Entladung unter Berücksichtigung des Beladungs- und Entladungsortes?\n",
        "\n",
        "Wie sieht das Transportnetz vom Jahr 2022 in Form einer Karte aus?"
      ],
      "metadata": {
        "id": "SBizgTEn-_OI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Gibt es eine Saisonalität/sich wiederholendes Muster in den Strassentransporten (Halbfertigfabrikaten und den Rohmaterialien) von FTL, LTL und Stückgutladungen? \n",
        "\n",
        "(Fokus auf das Produktionswerk in St. Margrethen, CH-9430)\n",
        "\n",
        "Transporte von/nach STAR (St. Margrethen, CH-9430) im Jahr 2022/2021"
      ],
      "metadata": {
        "id": "jkMoQUuRhloX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "E7HeS4HxFliJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Allgemeine Informationen"
      ],
      "metadata": {
        "id": "0xyMF5ohGvUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows2021 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2021) & (df['Entladungsdatum'].dt.year == 2021)].shape[0]\n",
        "\n",
        "print(\"The number of transports with start or end location CH and postal code 9430 is for year 2021:\", num_rows2021)"
      ],
      "metadata": {
        "id": "nefsYkgGG7bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows2022 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)].shape[0]\n",
        "\n",
        "print(\"The number of transports with start or end location CH and postal code 9430 is for year 2022:\", num_rows2022)"
      ],
      "metadata": {
        "id": "drqGhlaiHCRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "route_counts = df.groupby(['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']).size().reset_index(name='count')\n",
        "most_frequent_routes = route_counts.sort_values('count', ascending=False).head(3)\n",
        "print(\"The top 3 most frequent routes are:\")\n",
        "print(most_frequent_routes)"
      ],
      "metadata": {
        "id": "HZP-qv3QHPez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "route_counts = df.groupby(['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']).size().reset_index(name='count')\n",
        "most_frequent_routes_international = route_counts.query('Start_Land_ISO != Endstation_Land_ISO').sort_values('count', ascending=False).head(3)\n",
        "print(\"The top 3 most frequent international routes are:\")\n",
        "print(most_frequent_routes_international)"
      ],
      "metadata": {
        "id": "MA0SHki8HSvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anzahl Transporte die Enden/Starten an einem Produktionwerk"
      ],
      "metadata": {
        "id": "FUhseuw42_Ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time Series"
      ],
      "metadata": {
        "id": "ohic_0secuYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github von Daniel anschauen"
      ],
      "metadata": {
        "id": "RC19JX7ylhGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saisonalität in monatlichen Tonus?\n",
        "am Beispiel STAR"
      ],
      "metadata": {
        "id": "xz-pa8zakpRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for desired Start and End locations and year 2022\n",
        "filtered_M2022 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)]\n",
        "\n",
        "# Group the data by Transport-Kategorie and month, and count the number of transports for each group\n",
        "monthly_counts2022 = filtered_M2022.groupby([filtered_M2022['Beladungsdatum'].dt.to_period('M'), 'Transport-Kategorie']).size()\n",
        "\n",
        "# Create a list of the Transport-Kategorien and their corresponding colors and markers\n",
        "categories = ['Stückgut', 'LTL', 'FTL']\n",
        "colors = ['blue', 'green', 'red']\n",
        "markers = ['o', 's', 'd']\n",
        "\n",
        "# Plot the line chart\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    # Get the data for the current Transport-Kategorie\n",
        "    data = monthly_counts2022[:, category]\n",
        "    # Get the max and min values and their indices\n",
        "    max_val = data.max()\n",
        "    max_idx = data.idxmax()\n",
        "    min_val = data.min()\n",
        "    min_idx = data.idxmin()\n",
        "    # Convert the PeriodIndex to DatetimeIndex\n",
        "    x_axis = pd.to_datetime(data.index.to_timestamp())\n",
        "    # Plot the data for the current Transport-Kategorie\n",
        "    plt.plot(x_axis, data.values, color=colors[i], linestyle='--', label=category)\n",
        "    # Add a marker for the max and min values\n",
        "    plt.plot(max_idx, max_val, color=colors[i], marker=markers[i], markersize=10)\n",
        "    plt.text(max_idx.to_timestamp(), max_val+5, f\"Max: {max_val}\")\n",
        "    plt.plot(min_idx, min_val, color=colors[i], marker=markers[i], markersize=10)\n",
        "    plt.text(min_idx.to_timestamp(), min_val-20, f\"Min: {min_val}\")\n",
        "    \n",
        "# Set the x-axis tick frequency\n",
        "locator = mdates.AutoDateLocator(minticks=3, maxticks=10)\n",
        "ax.xaxis.set_major_locator(locator)\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
        "\n",
        "# Add labels and title to the plot\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Transports per Month')\n",
        "plt.title('Monthly Transports with Start or End Locations in CH 9430 - 2022 / STAR')\n",
        "\n",
        "# Add legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LIdXDiO4r5sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for desired Start and End locations and year 2022\n",
        "filtered_M2022 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)]\n",
        "\n",
        "# Group the data by Transport-Kategorie and month, and count the number of transports for each group\n",
        "monthly_counts2022 = filtered_M2022.groupby([filtered_M2022['Beladungsdatum'].dt.to_period('M'), 'Transport-Kategorie']).size()\n",
        "\n",
        "# Calculate overall average for each category\n",
        "avg_counts = monthly_counts2022.groupby('Transport-Kategorie').mean()\n",
        "\n",
        "# Create a list of the Transport-Kategorien and their corresponding colors and markers\n",
        "categories = ['Stückgut', 'LTL', 'FTL']\n",
        "colors = ['blue', 'green', 'red']\n",
        "markers = ['o', 's', 'd']\n",
        "\n",
        "# Plot the line chart\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    # Get the data for the current Transport-Kategorie\n",
        "    data = monthly_counts2022[:, category]\n",
        "\n",
        "    # Convert the PeriodIndex to DatetimeIndex\n",
        "    x_axis = pd.to_datetime(data.index.to_timestamp())\n",
        "    # Plot the data for the current Transport-Kategorie\n",
        "    plt.plot(x_axis, data.values, color=colors[i], linestyle='--', label=category)\n",
        "    # Add overall average as text next to the line\n",
        "    avg_val = avg_counts[category]\n",
        "    plt.text(x_axis[-1] + pd.DateOffset(months=1), data.values[-1], f\"Avg: {avg_val:.1f}\", va='center', color=colors[i])\n",
        "\n",
        "    \n",
        "# Set the x-axis tick frequency\n",
        "locator = mdates.AutoDateLocator(minticks=3, maxticks=10)\n",
        "ax.xaxis.set_major_locator(locator)\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
        "\n",
        "# Add labels and title to the plot\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Transports per Month')\n",
        "plt.title('Monthly Transports STAR - 2022')\n",
        "\n",
        "# Add legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rB80UHYqwVZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saisonalität in wöchentlichen Tonus?\n",
        "\n",
        "am Beispiel STAR / STAG"
      ],
      "metadata": {
        "id": "Ms4ILnSfkfQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only the rows with the specified start or end location and year STAR\n",
        "filtered_df2022 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)]\n",
        "\n",
        "# Create a new column for the week number of the loading or unloading date\n",
        "filtered_df2022['Kalenderwoche'] = filtered_df2022[['Beladungsdatum', 'Entladungsdatum']].apply(lambda x: min(x).week, axis=1)\n",
        "\n",
        "# Group the DataFrame by week number and count the number of rows in each group\n",
        "transports_per_week2022 = filtered_df2022.groupby('Kalenderwoche').size()\n",
        "\n",
        "# Calculate the average number of transports per week\n",
        "average_transports_per_week2022 = transports_per_week2022.mean()\n",
        "transports_per_week2022.head()\n"
      ],
      "metadata": {
        "id": "4BlMxsTYOE4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only the rows with the specified start or end location and year\n",
        "filtered_df2021 = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') | (df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430')) & (df['Beladungsdatum'].dt.year == 2021) & (df['Entladungsdatum'].dt.year == 2021)]\n",
        "\n",
        "# Create a new column for the week number of the loading or unloading date\n",
        "filtered_df2021['Kalenderwoche'] = filtered_df2021[['Beladungsdatum', 'Entladungsdatum']].apply(lambda x: min(x).week, axis=1)\n",
        "\n",
        "# Group the DataFrame by week number and count the number of rows in each group\n",
        "transports_per_week2021 = filtered_df2021.groupby('Kalenderwoche').size()\n",
        "\n",
        "# Calculate the average number of transports per week\n",
        "average_transports_per_week2021 = transports_per_week2021.mean()\n",
        "transports_per_week2021.head()"
      ],
      "metadata": {
        "id": "ZbuLHvStjnrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Produktionswerk STAR 2022"
      ],
      "metadata": {
        "id": "VpgMOvCuPY7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the number of transports per week\n",
        "\n",
        "transports_per_week = filtered_df2022.groupby('Kalenderwoche').size().reset_index(name='transports')\n",
        "\n",
        "#Calculate the trend line using linear regression\n",
        "\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(transports_per_week['Kalenderwoche'], transports_per_week['transports'])\n",
        "trend_line = intercept + slope * transports_per_week['Kalenderwoche']\n",
        "\n",
        "#Calculate the average number of transports per week\n",
        "\n",
        "average_transports_per_week = transports_per_week['transports'].mean()\n",
        "\n",
        "#Set the style and create a figure with a size of 14x8 inches\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "#Create a line plot of the number of transports per week with trend line\n",
        "\n",
        "sns.lineplot(data=transports_per_week, x=\"Kalenderwoche\", y=\"transports\", ax=ax)\n",
        "sns.lineplot(x=transports_per_week['Kalenderwoche'], y=trend_line, color='black', label='Trend Line', ax=ax)\n",
        "\n",
        "#Add markers for the minimum and maximum values\n",
        "\n",
        "min_week = transports_per_week.loc[transports_per_week['transports'].idxmin(), 'Kalenderwoche']\n",
        "max_week = transports_per_week.loc[transports_per_week['transports'].idxmax(), 'Kalenderwoche']\n",
        "min_transports = transports_per_week['transports'].min()\n",
        "max_transports = transports_per_week['transports'].max()\n",
        "ax.plot(min_week, min_transports, marker='o', markersize=10, color='green')\n",
        "ax.plot(max_week, max_transports, marker='o', markersize=10, color='red')\n",
        "\n",
        "#Add text annotations for the minimum and maximum values\n",
        "\n",
        "ax.annotate(f\"Min: {min_transports}\", xy=(min_week, min_transports), xytext=(-30, 30),\n",
        "textcoords='offset points', ha='center', va='bottom', color='green',\n",
        "arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5', color='green'))\n",
        "ax.annotate(f\"Max: {max_transports}\", xy=(max_week, max_transports), xytext=(30, -30),\n",
        "textcoords='offset points', ha='center', va='top', color='red',\n",
        "arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.5', color='red'))\n",
        "\n",
        "#Add a text annotation for the average number of transports per week\n",
        "\n",
        "ax.annotate(f\"Average: {average_transports_per_week:.2f}\", xy=(0.95, 0.05), xycoords='axes fraction', ha='right', va='bottom', fontsize=14)\n",
        "\n",
        "#Add a title, subtitle, and axis labels\n",
        "\n",
        "ax.set_title(\"Anzahl Transporte in 2022 von/nach STAR\", fontsize=16)\n",
        "ax.set_xlabel(\"Kalenderwoche\", fontsize=14)\n",
        "ax.set_ylabel(\"Anzahl Transporte\", fontsize=14)\n",
        "ax.text(0.5, -0.2, \"Disclaimer:\\nPlease note that the number of transports presented in this plot does not include cases where a transport arrives and simultaneously unloads and loads goods. In such cases, the transport is recorded as two separate transports instead of one.\",\n",
        "horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)"
      ],
      "metadata": {
        "id": "gCxsC3w4nN4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durchschnittlich finden pro Kalenderwoche 106 Transporte statt die im Produktionswerk STAR eintreffen. Der Einbruch in Kalenderwoche 31 muss in Rücksprache mit der Transportabteilung angeschaut werden. Der Einbruch am ENde des Jahres ist auf die Betriebsferien zurückzuführen die über Weihnachten-Neujahr stattfinden.\n",
        "\n",
        "Trendlinie zeigt, dass die Anzahl Transporte zunehmend sind."
      ],
      "metadata": {
        "id": "P_V4v_GJPeK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Boxplot pro Monat als Time Series"
      ],
      "metadata": {
        "id": "WvP3F208gd9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### FTL, LTL, Stückgut"
      ],
      "metadata": {
        "id": "5p_oXXkUPIwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom color palette\n",
        "palette = {'Stückgut': '#1f77b4', 'LTL': '#ff7f0e', 'FTL': '#2ca02c'}\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only the rows with the specified start or end location\n",
        "filtered_df = df[((df['Production Site Start'] == 'STAR') | (df['Production Site Endstation'] == 'STAR'))  & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)]\n",
        "\n",
        "# Create a new column for the week number of the loading or unloading date\n",
        "filtered_df['week'] = filtered_df[['Beladungsdatum', 'Entladungsdatum']].apply(lambda x: min(x).isocalendar()[1], axis=1)\n",
        "\n",
        "# Group the DataFrame by week number and transport category, and count the number of rows in each group\n",
        "transports_per_week = filtered_df.groupby(['week', 'Transport-Kategorie']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate the average number of transports per week for each category\n",
        "avg_counts = transports_per_week.groupby('Transport-Kategorie')['count'].mean().reset_index(name='average')\n",
        "\n",
        "# Plot the number of transports per week for each category\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.lineplot(data=transports_per_week, x='week', y='count', hue='Transport-Kategorie', palette=palette, ci=None, ax=ax)\n",
        "\n",
        "# Add trend line for each category\n",
        "for cat, group in transports_per_week.groupby('Transport-Kategorie'):\n",
        "    sns.regplot(x='week', y='count', data=group, order=1, ci=None, ax=ax, label=None)\n",
        "\n",
        "# Add average number next to each plot\n",
        "for i, row in avg_counts.iterrows():\n",
        "    cat = row['Transport-Kategorie']\n",
        "    avg_count = row['average']\n",
        "    ax.text(transports_per_week['week'].iloc[-1] + 1, transports_per_week[transports_per_week['Transport-Kategorie'] == cat]['count'].iloc[-1], f'Avg. {cat}: {avg_count:.1f}', color=palette[cat])\n",
        "\n",
        "\n",
        "ax.set_title(\"Anzahl Transporte pro Woche in 2022 von/nach STAR\", fontsize=16)\n",
        "ax.set_xlabel('Kalenderwoche')\n",
        "ax.set_ylabel('Anzahl Transporte')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6pBlXmQPhv8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Produktionswerk STAG 2022"
      ],
      "metadata": {
        "id": "Fc8h47dkRWoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only transports to or from STAG in 2022\n",
        "filtered_df2022_STAG = df[((df['Production Site Start'] == 'STAG') | (df['Production Site Endstation'] == 'STAG')) & (df['Beladungsdatum'].dt.year == 2022) & (df['Entladungsdatum'].dt.year == 2022)]\n",
        "\n",
        "# Create a new column for the week number of the loading or unloading date\n",
        "filtered_df2022_STAG['Kalenderwoche'] = filtered_df2022_STAG[['Beladungsdatum', 'Entladungsdatum']].apply(lambda x: min(x).week, axis=1)\n",
        "\n",
        "# Group the DataFrame by week number and count the number of rows in each group\n",
        "transports_per_week2022_STAG = filtered_df2022_STAG.groupby('Kalenderwoche').size()\n",
        "\n",
        "# Calculate the average number of transports per week\n",
        "average_transports_per_week2022_STAG = transports_per_week2022_STAG.mean()\n",
        "\n",
        "#Calculate the number of transports per week\n",
        "transports_per_week_STAG = filtered_df2022_STAG.groupby('Kalenderwoche').size().reset_index(name='transports')\n",
        "\n",
        "#Calculate the trend line using linear regression\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(transports_per_week_STAG['Kalenderwoche'], transports_per_week_STAG['transports'])\n",
        "trend_line = intercept + slope * transports_per_week_STAG['Kalenderwoche']\n",
        "\n",
        "#Calculate the average number of transports per week\n",
        "average_transports_per_week_STAG = transports_per_week_STAG['transports'].mean()\n",
        "\n",
        "#Set the style and create a figure with a size of 14x8 inches\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "#Create a line plot of the number of transports per week with trend line\n",
        "sns.lineplot(data=transports_per_week_STAG, x=\"Kalenderwoche\", y=\"transports\", ax=ax)\n",
        "sns.lineplot(x=transports_per_week_STAG['Kalenderwoche'], y=trend_line, color='black', label='Trend Line', ax=ax)\n",
        "\n",
        "#Add markers for the minimum and maximum values\n",
        "min_week = transports_per_week_STAG.loc[transports_per_week_STAG['transports'].idxmin(), 'Kalenderwoche']\n",
        "max_week = transports_per_week_STAG.loc[transports_per_week_STAG['transports'].idxmax(), 'Kalenderwoche']\n",
        "min_transports = transports_per_week_STAG['transports'].min()\n",
        "max_transports = transports_per_week_STAG['transports'].max()\n",
        "ax.plot(min_week, min_transports, marker='o', markersize=10, color='green')\n",
        "ax.plot(max_week, max_transports, marker='o', markersize=10, color='red')\n",
        "\n",
        "#Add text annotations for the minimum and maximum values\n",
        "ax.annotate(f\"Min: {min_transports}\", xy=(min_week, min_transports), xytext=(-30, 30),\n",
        "            textcoords='offset points', ha='center', va='bottom', color='green',\n",
        "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5', color='green'))\n",
        "ax.annotate(f\"Max: {max_transports}\", xy=(max_week, max_transports), xytext=(30, -30),\n",
        "            textcoords='offset points', ha='center', va='top', color='red',\n",
        "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.5', color='red'))\n",
        "\n",
        "#Add a text annotation for the average number of transports per week\n",
        "ax.annotate(f\"Average: {average_transports_per_week_STAG:.2f}\", xy=(0.95, 0.05), xycoords='axes fraction', ha='right', va='bottom', fontsize=14)\n",
        "\n",
        "#Add a title, subtitle, and axis labels\n",
        "ax.set_title(\"Number of Transports per Week in 2022 from/to STAG\", fontsize=16)\n",
        "ax.set_xlabel(\"Kalenderwoche\", fontsize=14)\n",
        "ax.set_ylabel(\"Number of Transports\", fontsize=14)\n",
        "ax.text"
      ],
      "metadata": {
        "id": "bNuWg1GzKjko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Produktionswerk STAR 2021"
      ],
      "metadata": {
        "id": "WNfecFllR0oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the number of transports per week\n",
        "\n",
        "transports_per_week = filtered_df2021.groupby('Kalenderwoche').size().reset_index(name='transports')\n",
        "\n",
        "#Calculate the trend line using linear regression\n",
        "\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(transports_per_week['Kalenderwoche'], transports_per_week['transports'])\n",
        "trend_line = intercept + slope * transports_per_week['Kalenderwoche']\n",
        "\n",
        "#Calculate the average number of transports per week\n",
        "\n",
        "average_transports_per_week = transports_per_week['transports'].mean()\n",
        "\n",
        "#Set the style and create a figure with a size of 14x8 inches\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "#Create a line plot of the number of transports per week with trend line\n",
        "\n",
        "sns.lineplot(data=transports_per_week, x=\"Kalenderwoche\", y=\"transports\", ax=ax)\n",
        "sns.lineplot(x=transports_per_week['Kalenderwoche'], y=trend_line, color='black', label='Trend Line', ax=ax)\n",
        "\n",
        "#Add markers for the minimum and maximum values\n",
        "\n",
        "min_week = transports_per_week.loc[transports_per_week['transports'].idxmin(), 'Kalenderwoche']\n",
        "max_week = transports_per_week.loc[transports_per_week['transports'].idxmax(), 'Kalenderwoche']\n",
        "min_transports = transports_per_week['transports'].min()\n",
        "max_transports = transports_per_week['transports'].max()\n",
        "ax.plot(min_week, min_transports, marker='o', markersize=10, color='green')\n",
        "ax.plot(max_week, max_transports, marker='o', markersize=10, color='red')\n",
        "\n",
        "#Add text annotations for the minimum and maximum values\n",
        "\n",
        "ax.annotate(f\"Min: {min_transports}\", xy=(min_week, min_transports), xytext=(-30, 30),\n",
        "textcoords='offset points', ha='center', va='bottom', color='green',\n",
        "arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5', color='green'))\n",
        "ax.annotate(f\"Max: {max_transports}\", xy=(max_week, max_transports), xytext=(30, -30),\n",
        "textcoords='offset points', ha='center', va='top', color='red',\n",
        "arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.5', color='red'))\n",
        "\n",
        "#Add a text annotation for the average number of transports per week\n",
        "\n",
        "ax.annotate(f\"Average: {average_transports_per_week:.2f}\", xy=(0.95, 0.05), xycoords='axes fraction', ha='right', va='bottom', fontsize=14)\n",
        "\n",
        "#Add a title, subtitle, and axis labels\n",
        "\n",
        "ax.set_title(\"Number of Transports per Week in 2021 from/to STAR\", fontsize=16)\n",
        "ax.set_xlabel(\"Kalenderwoche\", fontsize=14)\n",
        "ax.set_ylabel(\"Number of Transports\", fontsize=14)\n",
        "ax.text(0.5, -0.2, \"Disclaimer:\\nPlease note that the number of transports presented in this plot does not include cases where a transport arrives and simultaneously unloads and loads goods. In such cases, the transport is recorded as two separate transports instead of one.\",\n",
        "horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)"
      ],
      "metadata": {
        "id": "IE6fSMDPnk9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### FTL, LTL, Stückgut"
      ],
      "metadata": {
        "id": "dUCDDeOHRqYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom color palette\n",
        "palette = {'Stückgut': '#1f77b4', 'LTL': '#ff7f0e', 'FTL': '#2ca02c'}\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only the rows with the specified start or end location\n",
        "filtered_df = df[((df['Start_Land_ISO'] == 'CH') & (df['Start_PLZ'] == '9430') & (df['Beladungsdatum'].dt.year == 2021)) | ((df['Endstation_Land_ISO'] == 'CH') & (df['Endstation_PLZ'] == '9430') & (df['Beladungsdatum'].dt.year == 2021))]\n",
        "\n",
        "# Create a new column for the week number of the loading or unloading date\n",
        "filtered_df['week'] = filtered_df[['Beladungsdatum', 'Entladungsdatum']].apply(lambda x: min(x).isocalendar()[1], axis=1)\n",
        "\n",
        "# Group the DataFrame by week number and transport category, and count the number of rows in each group\n",
        "transports_per_week = filtered_df.groupby(['week', 'Transport-Kategorie']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate the average number of transports per week for each category\n",
        "avg_counts = transports_per_week.groupby('Transport-Kategorie')['count'].mean().reset_index(name='average')\n",
        "\n",
        "# Plot the number of transports per week for each category\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.lineplot(data=transports_per_week, x='week', y='count', hue='Transport-Kategorie', palette=palette, ci=None, ax=ax)\n",
        "\n",
        "# Add trend line for each category\n",
        "for cat, group in transports_per_week.groupby('Transport-Kategorie'):\n",
        "    sns.regplot(x='week', y='count', data=group, order=1, ci=None, ax=ax, label=None)\n",
        "\n",
        "# Add average number next to each plot\n",
        "for i, row in avg_counts.iterrows():\n",
        "    cat = row['Transport-Kategorie']\n",
        "    avg_count = row['average']\n",
        "    ax.text(transports_per_week['week'].iloc[-1] + 1, transports_per_week[transports_per_week['Transport-Kategorie'] == cat]['count'].iloc[-1], f'Avg. {cat}: {avg_count:.1f}', color=palette[cat])\n",
        "\n",
        "ax.set_title(\"Number of Transports per Week in 2021 from/to STAR\", fontsize=16)\n",
        "ax.set_xlabel('Week number')\n",
        "ax.set_ylabel('Number of transports')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCrRAqljn5XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Frequency of routes"
      ],
      "metadata": {
        "id": "_5_REsiWzNrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by production site and count the number of rows\n",
        "counts = df.groupby('Production Site Start').count()['Start_Land_ISO']\n",
        "\n",
        "# Plot the counts as a bar chart\n",
        "plt.bar(counts.index, counts.values)\n",
        "\n",
        "# Add labels and title to the plot\n",
        "plt.xlabel('Production Site')\n",
        "plt.ylabel('Number of Transports')\n",
        "plt.title('Number of Transports by Production Site')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BVlAq0Y7zjog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by production site and count the number of rows\n",
        "counts = df.groupby('Production Site Endstation').count()['Start_Land_ISO']\n",
        "\n",
        "# Plot the counts as a bar chart\n",
        "plt.bar(counts.index, counts.values)\n",
        "\n",
        "# Add labels and title to the plot\n",
        "plt.xlabel('Production Site')\n",
        "plt.ylabel('Number of Transports')\n",
        "plt.title('Number of Transports by Production Site')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jkc-MiEj-IRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dataframe for the three most frequent international routes\n",
        "most_frequent_routes = most_frequent_routes_international[['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']]\n",
        "df_filtered = df[df[['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']].apply(tuple, axis=1).isin(most_frequent_routes.apply(tuple, axis=1))]\n",
        "\n",
        "# Group by month and route to get total count for each month\n",
        "df_filtered['month'] = df_filtered['Beladungsdatum'].dt.month\n",
        "grouped = df_filtered.groupby(['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ', 'month']).size().reset_index(name='count')\n",
        "\n",
        "# Create line plot for each route\n",
        "for route in most_frequent_routes.values:\n",
        "    route_filtered = grouped[(grouped['Start_Land_ISO'] == route[0]) & (grouped['Start_PLZ'] == route[1]) & (grouped['Endstation_Land_ISO'] == route[2]) & (grouped['Endstation_PLZ'] == route[3])]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=route_filtered, x='month', y='count')\n",
        "    plt.title(f\"Route: {route[0]} {route[1]} - {route[2]} {route[3]}\")\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1kHH1y1aDRrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dataframe for the three most frequent international routes\n",
        "most_frequent_routes = most_frequent_routes_international[['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']]\n",
        "df_filtered = df.loc[df[['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ']].apply(tuple, axis=1).isin(most_frequent_routes.apply(tuple, axis=1))]\n",
        "\n",
        "# Group by week and route to get total count for each week\n",
        "df_filtered['week'] = df_filtered['Beladungsdatum'].dt.isocalendar().week\n",
        "grouped = df_filtered.groupby(['Start_Land_ISO', 'Start_PLZ', 'Endstation_Land_ISO', 'Endstation_PLZ', 'week']).size().reset_index(name='count')\n",
        "\n",
        "# Create line plot for each route\n",
        "for route in most_frequent_routes.values:\n",
        "    route_filtered = grouped.loc[(grouped['Start_Land_ISO'] == route[0]) & (grouped['Start_PLZ'] == route[1]) & (grouped['Endstation_Land_ISO'] == route[2]) & (grouped['Endstation_PLZ'] == route[3])]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=route_filtered, x='week', y='count')\n",
        "    plt.title(f\"Route: {route[0]} {route[1]} - {route[2]} {route[3]}\")\n",
        "    plt.xlabel('Week')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "PnSMan8uE_iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter the dataframe by category 'Stückgut' and production site 'STAR'\n",
        "df_stueckgut_star = df[(df['Transport-Kategorie'] == 'Stückgut') & \n",
        "                       (df['Production Site Start'] == 'STAR') & \n",
        "                       (df['Endstation_Land_ISO'] != 'CH')]\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_stueckgut_star.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency').sort_values('Frequency', ascending=False)\n",
        "\n",
        "# Create the bar chart figure and axis\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "\n",
        "# Plot the bar chart\n",
        "sns.barplot(x='Frequency', y='Start_Land_ISO', hue='Endstation_Land_ISO', data=freq_table)\n",
        "\n",
        "# Set the title of the bar chart\n",
        "ax.set_title(\"Frequency of Stückgut Transport Routes starting at STAR production site\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZeEERBSvP5C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Häufigkeit anhand von Heatmaps"
      ],
      "metadata": {
        "id": "R8m0O_-dV5KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe by category 'FTL'\n",
        "df_ftl = df[df['Transport-Kategorie'] == 'FTL']\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_ftl.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency')\n",
        "\n",
        "# Reshape the dataset using pivot()\n",
        "pivot_table = freq_table.pivot('Start_Land_ISO', 'Endstation_Land_ISO', 'Frequency')\n",
        "freq_table.head()\n",
        "# Create heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(pivot_table, annot=True, cmap='Blues', linewidths=.2, ax=ax)\n",
        "\n",
        "# Add axis labels and title\n",
        "ax.set_xlabel('Destination')\n",
        "ax.set_ylabel('Origin')\n",
        "ax.set_title('Häufigkeit von FTL-Transportrouten nach Ländercodes')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BlDBgbZcm3KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe by category 'FTL'\n",
        "df_ftl = df[df['Transport-Kategorie'] == 'FTL']\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_ftl.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency').sort_values('Frequency', ascending=False)\n",
        "\n",
        "# Reshape the dataset using pivot()\n",
        "pivot_table = freq_table.pivot('Start_Land_ISO', 'Endstation_Land_ISO', 'Frequency')\n",
        "print(freq_table)\n"
      ],
      "metadata": {
        "id": "MfEvwP5aAmCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter the dataframe by category 'FTL'\n",
        "df_ftl = df[df['Transport-Kategorie'] == 'FTL']\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_ftl.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency').sort_values('Frequency', ascending=False)\n",
        "\n",
        "# Reshape the dataset using pivot()\n",
        "pivot_table = freq_table.pivot('Start_Land_ISO', 'Endstation_Land_ISO', 'Frequency')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n",
        "\n",
        "ax.set_title(\"Häufigkeit von FTL-Transportrouten nach Ländercodes\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Bi2jdeQ4PZ4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter the dataframe by category 'LTL'\n",
        "df_ftl = df[df['Transport-Kategorie'] == 'LTL']\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_ftl.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency').sort_values('Frequency', ascending=False)\n",
        "\n",
        "# Reshape the dataset using pivot()\n",
        "pivot_table = freq_table.pivot('Start_Land_ISO', 'Endstation_Land_ISO', 'Frequency')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n",
        "\n",
        "ax.set_title(\"Häufigkeit von FTL-Transportrouten nach Ländercodes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kMnnNwspV9Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter the dataframe by category 'Stückgut'\n",
        "df_ftl = df[df['Transport-Kategorie'] == 'Stückgut']\n",
        "\n",
        "# Get the frequency of each combination of starting and ending points\n",
        "freq_table = df_ftl.groupby(['Start_Land_ISO', 'Endstation_Land_ISO']).size().reset_index(name='Frequency').sort_values('Frequency', ascending=False)\n",
        "\n",
        "# Reshape the dataset using pivot()\n",
        "pivot_table = freq_table.pivot('Start_Land_ISO', 'Endstation_Land_ISO', 'Frequency')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n",
        "\n",
        "ax.set_title(\"Häufigkeit von FTL-Transportrouten nach Ländercodes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qLKbagrJ4GS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Karte"
      ],
      "metadata": {
        "id": "m3IVbYrsdiLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopy "
      ],
      "metadata": {
        "id": "qtd0OuyWmha2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas descartes"
      ],
      "metadata": {
        "id": "Cc9AinnlmhUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycountry\n",
        "import pandas as pd\n",
        "\n",
        "# ISO-Codes definieren\n",
        "iso_codes = ['NL', 'NO', 'BA', 'SI', 'BH', 'IT', 'HU', 'FR', 'FI', 'DE', 'AU', 'BE', 'BG', 'CZ', 'GB', 'BY', 'DK', 'ES', 'SE', 'RO', 'LU', 'TR', 'EE', 'LT', 'HR', 'SK', 'GE', 'CH', 'PL', 'RS', 'MK', 'AD', 'AT', 'SB']\n",
        "\n",
        "# Ländernamen aus den ISO-Codes extrahieren\n",
        "country_names = [pycountry.countries.get(alpha_2=iso_code).name for iso_code in iso_codes]\n",
        "\n",
        "# DataFrame erstellen\n",
        "df = pd.DataFrame({'ISO_Code': iso_codes, 'Country_Name': country_names})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2d_sOuJvmEp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.exc import GeocoderTimedOut\n",
        "from geopy.geocoders import Nominatim\n",
        "   \n",
        "# declare an empty list to store\n",
        "# latitude and longitude of values \n",
        "# of city column\n",
        "longitude = []\n",
        "latitude = []\n",
        "   \n",
        "# function to find the coordinate\n",
        "# of a given city \n",
        "def findGeocode(country_name):\n",
        "       \n",
        "    # try and catch is used to overcome\n",
        "    # the exception thrown by geolocator\n",
        "    # using geocodertimedout  \n",
        "    try:\n",
        "          \n",
        "        # Specify the user_agent as your\n",
        "        # app name it should not be none\n",
        "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
        "          \n",
        "        return geolocator.geocode(country_name)\n",
        "      \n",
        "    except GeocoderTimedOut:\n",
        "          \n",
        "        return findGeocode(country_name)    \n",
        "  \n",
        "# each value from city column\n",
        "# will be fetched and sent to\n",
        "# function find_geocode   \n",
        "for i in (df[\"Country_Name\"]):\n",
        "      \n",
        "    if findGeocode(i) != None:\n",
        "           \n",
        "        loc = findGeocode(i)\n",
        "          \n",
        "        # coordinates returned from \n",
        "        # function is stored into\n",
        "        # two separate list\n",
        "        latitude.append(loc.latitude)\n",
        "        longitude.append(loc.longitude)\n",
        "       \n",
        "    # if coordinate for a city not\n",
        "    # found, insert \"NaN\" indicating \n",
        "    # missing value \n",
        "    else:\n",
        "        latitude.append(np.nan)\n",
        "        longitude.append(np.nan)"
      ],
      "metadata": {
        "id": "8-waRWP7kn_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now add this column to dataframe\n",
        "df[\"Longitude\"] = longitude\n",
        "df[\"Latitude\"] = latitude\n",
        "  \n",
        "df"
      ],
      "metadata": {
        "id": "C3B0NkkJkqlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.exc import GeocoderTimedOut\n",
        "from geopy.geocoders import Nominatim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# declare an empty list to store\n",
        "# latitude and longitude of values \n",
        "# of city column\n",
        "longitude = []\n",
        "latitude = []\n",
        "   \n",
        "# function to find the coordinate\n",
        "# of a given city \n",
        "def findGeocode(country_name):\n",
        "       \n",
        "    # try and catch is used to overcome\n",
        "    # the exception thrown by geolocator\n",
        "    # using geocodertimedout  \n",
        "    try:\n",
        "          \n",
        "        # Specify the user_agent as your\n",
        "        # app name it should not be none\n",
        "        geolocator = Nominatim(user_agent=\"your_app_name\")\n",
        "          \n",
        "        return geolocator.geocode(country_name)\n",
        "      \n",
        "    except GeocoderTimedOut:\n",
        "          \n",
        "        return findGeocode(country_name)    \n",
        "  \n",
        "# each value from city column\n",
        "# will be fetched and sent to\n",
        "# function find_geocode   \n",
        "for i in (df[\"Country_Name\"]):\n",
        "      \n",
        "    if findGeocode(i) != None:\n",
        "           \n",
        "        loc = findGeocode(i)\n",
        "          \n",
        "        # coordinates returned from \n",
        "        # function is stored into\n",
        "        # two separate list\n",
        "        latitude.append(loc.latitude)\n",
        "        longitude.append(loc.longitude)\n",
        "       \n",
        "    # if coordinate for a city not\n",
        "    # found, insert \"NaN\" indicating \n",
        "    # missing value \n",
        "    else:\n",
        "        latitude.append(np.nan)\n",
        "        longitude.append(np.nan)\n",
        "\n",
        "# create a DataFrame with the Country name, longitude, and latitude\n",
        "country_df = pd.DataFrame({'Country': df[\"Country_Name\"], 'Longitude': longitude, 'Latitude': latitude})\n",
        "\n",
        "# drop any rows with missing values\n",
        "country_df = country_df.dropna()\n",
        "\n",
        "# print the DataFrame\n",
        "print(country_df)"
      ],
      "metadata": {
        "id": "pQGnoXJGkujo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Karten-Daten herunterladen\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "# DataFrame mit Längen- und Breitengrad-Daten erstellen\n",
        "df = country_df\n",
        "\n",
        "# Koordinaten als Punkte speichern\n",
        "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
        "geo_df = gpd.GeoDataFrame(df, geometry=geometry)\n",
        "\n",
        "# Karte erstellen\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "\n",
        "# Karte zeichnen\n",
        "world.plot(ax=ax, alpha=0.4, color='grey')\n",
        "\n",
        "# Markierungen zeichnen\n",
        "geo_df.plot(ax=ax, markersize=50, color='blue', marker='o')\n",
        "\n",
        "# Achsen ausblenden\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Titel hinzufügen\n",
        "ax.set_title('Länder-Markierungen')\n",
        "\n",
        "# Anzeigen der Karte\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7EnjWQbrkxlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Karten-Daten herunterladen\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "# DataFrame mit Längen- und Breitengrad-Daten erstellen\n",
        "df = country_df\n",
        "\n",
        "# Koordinaten als Punkte speichern\n",
        "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
        "geo_df = gpd.GeoDataFrame(df, geometry=geometry)\n",
        "\n",
        "# Karte erstellen\n",
        "fig, ax = plt.subplots(figsize=(100,10))\n",
        "\n",
        "# Karte zeichnen\n",
        "world.plot(ax=ax, alpha=0.4, color='grey')\n",
        "\n",
        "# Markierungen zeichnen\n",
        "geo_df.plot(ax=ax, markersize=80, column='Country', cmap='Set2', legend=True)\n",
        "\n",
        "# Achsen ausblenden\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Titel hinzufügen\n",
        "ax.set_title('Start- und Endstationland')\n",
        "\n",
        "# Anzeigen der Karte\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YkTk9iRTn5sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Karten-Daten herunterladen\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "# DataFrame mit Längen- und Breitengrad-Daten erstellen\n",
        "df = country_df\n",
        "\n",
        "# Koordinaten als Punkte speichern\n",
        "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
        "geo_df = gpd.GeoDataFrame(df, geometry=geometry)\n",
        "\n",
        "# Karte erstellen\n",
        "fig, ax = plt.subplots(figsize=(100,10))\n",
        "\n",
        "# Karte zeichnen\n",
        "world.plot(ax=ax, alpha=0.4, color='grey')\n",
        "\n",
        "# Markierungen zeichnen und Ländernamen annotieren\n",
        "for country, geometry in zip(df['Country'], geo_df['geometry']):\n",
        "    x, y = geometry.x, geometry.y\n",
        "    ax.annotate(country, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize=5)\n",
        "\n",
        "# Achsen ausblenden\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Titel hinzufügen\n",
        "ax.set_title('Länder-Markierungen')\n",
        "\n",
        "# Anzeigen der Karte\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iu0FDmxhoq0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dCWXU5l-3hcv",
        "3LGiyKL73WIK",
        "T6MUmo7FiQD_",
        "kxLZyC39igIq",
        "iDTkxuJ6gD8b",
        "R6XX96ROjv1y",
        "j3BV1YfC-psX",
        "SBizgTEn-_OI",
        "0xyMF5ohGvUd",
        "xz-pa8zakpRo",
        "Ms4ILnSfkfQP",
        "VpgMOvCuPY7h",
        "Fc8h47dkRWoL",
        "WNfecFllR0oi"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}